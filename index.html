<!DOCTYPE html>
<html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

  <title>STEP - WebGL2 </title>

  <link rel="stylesheet" type="text/css" href="./css/jquery.dataTables.min.css" media="screen" />
  <script src="./js/jquery-2.1.4.min.js"></script>
  <script src="./js/jquery.dataTables.min.js"></script>
  <script src="./js/jszip.min.js"></script>

  <script type="text/javascript" src="./js/gl-matrix-min.js"></script>

  <script src="./js/pouchdb-5.1.0.js"></script>
  <script src="./js/pouchdb.memory.js"></script>

  <link rel="stylesheet" href="js/TF/ui.css"/>
  <script src="js/TF/ui.js"></script>
  <script src="js/TF/CP_widget.js"></script>
  <script src="js/TF/TF_panel.js"></script>


  <script type="text/javascript" src="../dcmio/FileSaver.min.js"></script>
  <script type="text/javascript" src="../dcmio/DicomMetaDictionary.js"></script>
  <script type="text/javascript" src="../dcmio/BufferStream.js"></script>
  <script type="text/javascript" src="../dcmio/ValueRepresentation.js"></script>
  <script type="text/javascript" src="../dcmio/Tag.js"></script>
  <script type="text/javascript" src="../dcmio/DicomMessage.js"></script>
  <script type="text/javascript" src="../dcmio/normalizers.js"></script>
  <script type="text/javascript" src="../dcmio/derivations.js"></script>
  <script type="text/javascript" src="../dcmio/colors.js"></script>

  <script type="text/javascript" src="./linear.js"></script>
  <script type="text/javascript" src="./commongl.js"></script>

  <script type="text/javascript" src="./fields/field.js"></script>
  <script type="text/javascript" src="./fields/fiducial.js"></script>
  <script type="text/javascript" src="./fields/pixel.js"></script>
  <script type="text/javascript" src="./fields/image.js"></script>
  <script type="text/javascript" src="./fields/segmentation.js"></script>
  <script type="text/javascript" src="./fields/transform.js"></script>

  <script type="text/javascript" src="./formats.js"></script>
  <script type="text/javascript" src="./slicer.js"></script>

  <script type="text/javascript" src="./view.js"></script>
  <script type="text/javascript" src="./generators.js"></script>
  <script type="text/javascript" src="./renderer.js"></script>
  <script type="text/javascript" src="./growcut.js"></script>
  <script type="text/javascript" src="./gaussian.js"></script>
  <script type="text/javascript" src="./bilateral.js"></script>
  <script type="text/javascript" src="./similarity.js"></script>
  <script type="text/javascript" src="./gabor.js"></script>
  <script type="text/javascript" src="./nonlocalmeans.js"></script>
  <script type="text/javascript" src="./pde.js"></script>
  <script type="text/javascript" src="./registration.js"></script>


  <link rel="stylesheet" href="./css/step.css" />
  <script type="text/javascript" src="./ui.js"></script>
  <script type="text/javascript" src="./ui.step.js"></script>

  <script type="text/javascript" src="./controls.js"></script>

  <script type="text/javascript" src="./chronicle.js"></script>

</head>

<body>

<canvas id="renderCanvas"></canvas>

<script>
'use strict'

let slicerURL = 'http://localhost:2016/slicer';

//
// Hard coded for the neurosurgical ultrasound experiment
//

// assumes:
// - specific volumes loaded
// - LandmarkRegistration performed with ThinPlateSpline
// - grid transform exported

function Patient3_setup() {


  let preduraID = 'vtkMRMLScalarVolumeNode1';
  let preMRID = 'vtkMRMLScalarVolumeNode2';
  let gridTransformID = 'vtkMRMLGridTransformNode1';

  let slicer = new Slicer({url: slicerURL});

  slicer.volume(preduraID).then(dataset=>{
    dataset.SeriesDescription = 'predura';
    loadDatasets([dataset]);
    slicer.volume(preMRID).then(dataset=>{
      dataset.SeriesDescription = 'preMR';
      loadDatasets([dataset]);
      step.renderer.inputFields[1].rgba = [0, 1, 0, 1]; // target is green
      slicer.transform(gridTransformID).then(transformDataset=>{
        let transformField = Field.fromDataset(transformDataset)[0];
        transformField.visible = 0;
        step.renderer.inputFields.unshift(transformField);
        step.renderer.inputFields[1].transformField = transformField; // predura

        step.renderer.inputFields.forEach(field => field.gradientOpacityScale = 0.);
        step.renderer.updateProgram();
        step.renderer.requestRender(step.view);
      });
    });
  });

  step.controls.tool = 'trackball';
  step.controls.gangWindow = 'trackball';
  step.view.viewNear = 0;
  step.view.viewFar = Linear.LARGE_NUMBER;
  step.uniforms.sliceMode.value = 0;
}

function Patient17_setup() {

  let premri1ID = 'vtkMRMLScalarVolumeNode1';
  let postdura1ID = 'vtkMRMLScalarVolumeNode2';
  let gridTransformID = 'Transform-grid';

  let slicer = new Slicer({url: slicerURL});

  slicer.volume(postdura1ID).then(dataset=>{
    dataset.SeriesDescription = 'postdura1';
    loadDatasets([dataset]);
    slicer.volume(premri1ID).then(dataset=>{
      dataset.SeriesDescription = 'premri1ID';
      loadDatasets([dataset]);
      slicer.transform(gridTransformID).then(transformDataset=>{
        step.renderer.inputFields[1].rgba = [0, 1, 0, 1]; // premri1 target is green
        let transformField = Field.fromDataset(transformDataset)[0];
        transformField.visible = 0;
        step.renderer.inputFields[0].transformField = transformField; // postdura1 is transformed
        step.renderer.inputFields.unshift(transformField);

        step.renderer.inputFields.forEach(field => field.gradientOpacityScale = 0.);
        step.renderer.updateProgram();
        step.renderer.requestRender(step.view);
      });
    });
  });

  step.controls.tool = 'trackball';
  step.controls.gangWindow = 'trackball';
  step.view.viewNear = 0;
  step.view.viewFar = Linear.LARGE_NUMBER;
  step.uniforms.sliceMode.value = 0;
}


// End hard coded neurosurgical ultrasound experiment


function crossFade(options={}) {

  options.timepoint = (options.timepoint == undefined) ? .5 : options.timepoint;
  options.fields = options.fields || step.renderer.inputFields;
  options.fields.forEach(field => {
    field.rgba[3] = 0;
  });
  let frameCount = options.fields.length;
  let frameTime = options.timepoint * frameCount;
  let frame = Math.floor(frameTime);
  let blend = frameTime - frame;
  options.fields[frame%frameCount].rgba[3] = 1. - blend;
  options.fields[(frame+1)%frameCount].rgba[3] = blend;
}


function loadNRRDFromURL(options={}) {
  options.url = options.url || 'https://s3.amazonaws.com/IsomicsPublic/SampleData/MRHead/MRHead.nrrd';
  let request = new XMLHttpRequest();
  request.responseType = 'arraybuffer';
  request.onload = function(event) {
    let nrrd = NRRD.parse(event.target.response);
    loadDatasets([NRRD.nrrdToDICOMDataset(nrrd)]);
  };
  request.onerror = console.error;
  request.open('GET', options.url, true);
  request.send();
}

function loadVolumeFromSlicer(options={}) {
  options.id = options.id || 'vtkMRMLScalarVolumeNode1';
  options.name = options.name || 'SlicerVolume1';
  // pull over a dataset from SlicerWeb and render it
  let slicer = new Slicer({url: slicerURL});
  slicer.volume(options.id).then(dataset=>{
    dataset.SeriesDescription = options.name;
    loadDatasets([dataset]);
  });
}

function loadVolumesFromSlicer(ids) {
  if (ids) {
    ids.forEach(loadVolumeFromSlicer);
  } else {
    let slicer = new Slicer({url: slicerURL});
    slicer.volumes().then(function(volumes) {
      volumes.forEach(volume => loadVolumeFromSlicer(volume));
    });
  }
}

function sendVolumesToSlicer(options={}) {
  // send currently visible fields to Slicer
  let slicer = new Slicer({url: slicerURL});
  step.renderer.inputFields.filter(field =>
    field.constructor.name == "ImageField" && field.visible
  ).forEach(field => {
    console.log('sending ', field);
    slicer.postPixelFieldAsVolume(field).then(console.log);
  });
}


// create a FiducialField from mrml fiducial nodes
function addFiducialNodes(fiducialNodes) {
  // currently makes one uniformly colored field
  // for all fiducial nodes
  let fiducials = [];
  let rgba;
  Object.values(fiducialNodes).forEach(fiducialNode => {
    rgba = fiducialNode.color.slice();
    rgba.push(1.);
    fiducialNode.markups.forEach(markup => {
      let point = markup.position.slice();
      point[0] *= -1; point[1] *= -1; // RAS to LPS
      fiducials.push(new Fiducial({
        point: point,
        radius: fiducialNode.scale / 2. + 0.000001,
      }));
    });
  });

  let fiducialField = new FiducialField({
    fiducials,
    rgba: rgba,
    opacityScale: 1.,
  });

  let bounds = step.renderer.bounds || {min: [-200,-200,-200], max: [200,200,200]};
  step.renderer.inputFields.push(fiducialField);
  step.renderer.updateProgram();
  step.renderer.requestRender(step.view);
}

// create or update fiducials
function fiducialsFromSlicer() {
  let slicer = new Slicer({url: slicerURL});
  slicer.fiducials().then(fiducialNodes => {
    // remove old fiducials
    step.renderer.inputFields = step.renderer.inputFields.filter(field => {
      return field.constructor.name != "FiducialField";
    });
    addFiducialNodes(fiducialNodes);
  });
}

function addRandomFiducials() {
  //
  // Initial field for rendering
  //
  function randomPoint(bounds) {
    let point = [];
    [0,1,2].forEach(e=>{
      let range = bounds.max[e] - bounds.min[e];
      point.push(bounds.min[e] + Math.random()*range);
    });
    console.log(bounds, point);
    return(point);
  }

  let fiducials = [];
  let bounds = {min: [-200,-200,-200], max: [200,200,200]};
  if (step.renderer.inputFields.length > 0) {
    bounds = step.renderer.bounds;
  }
  let size = 0.05 * bounds.max[0] - bounds.min[0];
  for (let index=0; index < 3; index++) {
    fiducials.push(new Fiducial({
      point: randomPoint(bounds),
      radius: size * Math.random(),
    }));
  }

  let fiducialField = new FiducialField({
    fiducials,
    rgba: [Math.random(), Math.random(), Math.random(), Math.random()],
    opacityScale: 1.,
  });

  step.renderer.inputFields.push(fiducialField);
  step.renderer.updateProgram();
  console.log(fiducialField);
  step.renderer.view.look({at: fiducialField.center, bounds: bounds});
  step.renderer.requestRender(step.view);
}

function addTransformField(options={}) {
  //
  // Create a vector transform field and apply it to all the renderers fields
  // - make a dummy dataset containing the transform
  // - - TODO: this isn't a proper Deformable Spatial Registration (yet)
  // - - see http://dicom.nema.org/medical/dicom/current/output/html/part03.html#sect_C.20.3
  // - convert it to a field
  // - add it to the renderer and set it as input field on other fields
  //

  options.referenceField = options.referenceField || step.renderer.inputFields[0];

  let referenceDataset = options.referenceField.dataset;
  let [w,h,d] = [referenceDataset.Columns, referenceDataset.Rows, referenceDataset.NumberOfFrames];
  let arrayElementCount = [w,h,d].reduce((p,e)=>p*e);
  let vectorGrid = new Float32Array(3 * arrayElementCount);
  let pixelMeasures = referenceDataset.SharedFunctionalGroups.PixelMeasures;
  let resolution = [pixelMeasures.PixelSpacing[1], pixelMeasures.PixelSpacing[0], pixelMeasures.SpacingBetweenSlices];

  let transformDataset = {
    SeriesDescription: "Deformation from addTransformField method",
    SOPClass: "DeformableSpatialRegistration",
    DeformableRegistration: {
      DeformableRegistrationGrid: {
        ImageOrientationPatient: referenceDataset.SharedFunctionalGroups.PlaneOrientation.ImageOrientationPatient,
        ImagePositionPatient: Array.prototype.slice.call(options.referenceField.pixelToPatient.slice(12,15)),
        GridDimensions: [w, h, d],
        GridResolution: resolution,
        VectorGridData: vectorGrid,
      },
    },
  };

  let transformField = Field.fromDataset(transformDataset)[0];
  transformField.visible = 1;
  options.referenceField.transformField = transformField;

  step.renderer.inputFields.unshift(transformField); // TODO: generalize dependencies
  step.renderer.updateProgram();
  step.renderer.requestRender(step.view);
}

function animateTransform(options={}) {
  // animate passed in field or first render field with a transform
  let animatingField = options.field || (() => {
    let returnField;
    step.renderer.inputFields.forEach(field => {
      if (field.transformField) {
        returnField = field;
      }
    });
    return returnField;
  })();
  let frame = 0;
  let frames = options.frames || 100;
  let maxGain = options.maxGain || 1;
  let animationFrame = function (now) {
    animatingField.transformGain = maxGain * Math.sin(Math.PI*frame/frames);
    step.renderer.requestRender();
    step.ui.bottomBar.progress = `Animation frame ${frame} of ${frames}`;
    frame = frame + 1;
    if (frame <= frames) {
      requestAnimationFrame(animationFrame)
    }
  };
  requestAnimationFrame(animationFrame)
}

// once the data is downloaded
function readDICOM(arrayBuffer) {
  let dicomData = DicomMessage.readFile(arrayBuffer);
  let dataset = DicomMetaDictionary.cleanDataset(dicomData.dict);
  dataset = DicomMetaDictionary.naturalizeDataset(dataset);
  dataset._meta = DicomMetaDictionary.namifyDataset(dicomData.meta);
  return (dataset);
}

function saveDICOM(dataset) {
  var blob = DicomMetaDictionary.datasetToBlob(dataset);
  saveAs(blob, "test.dcm", true);
}

function saveFieldsAsDICOM(fields, visibleOnly=true) {
  let zip = new JSZip();
  fields = fields || step.renderer.inputFields;
  fields.forEach(field => {
    if (visibleOnly) {
      if (!field.visible) {
        return;
      }
    }
    let fileName = `${field.dataset.SOPInstanceUID}.dcm`;
    console.log(`zipping ${fileName}`);
    step.ui.bottomBar.progress = `Blobbing ${fileName}`;
    let dicomBlob = DicomMetaDictionary.datasetToBlob(field.dataset);
    zip.file(fileName, dicomBlob);
  });
  console.log(`generating zip`);
  zip.generateAsync({type: "blob"})
    .then(contents => {
      console.log(`saving zip`, contents, contents.size);
      //TODO: crashes with data size 298956414
      window.saveAs(contents, "derivedDICOM.zip", true);
    });
}

function requestInstance(url, loaded) {
  let dataRequest = new XMLHttpRequest();
  dataRequest.responseType = "arraybuffer";
  dataRequest.onload = function (event) {
    let arrayBuffer = dataRequest.response;
    loaded(arrayBuffer);
  };
  dataRequest.open("GET", url, true);
  dataRequest.send(null);
}

function loadDatasets(datasets) {
  let dataset = Normalizer.normalizeToDataset(datasets);
  if (dataset == undefined) {
    console.error('Could not form normalized dataset from datasets');
    console.log(datasets);
    return;
  }
  let fields = Field.fromDataset(dataset);
  step.renderer.inputFields.push(...fields);
  step.renderer.updateProgram();
  let field = fields[0];
  step.renderer.view.look({at: field.center, bounds: field.bounds});
  if (!step.options.newVolumeThreeD) {
    step.view.slice({plane: "coronal", offset: 0.5, thickness: 1});
    step.uniforms.sliceMode.value = 1;
  }
  let lightOffset = [200, -200, 400];
  [0,1,2].forEach(index => {
    step.uniforms.pointLight.value[index] = step.view.viewPoint[index] + lightOffset[index];
  });
  step.renderer.requestRender(step.view);
}

function requestSeries(instanceURLs) {
  let seriesDatasets = [];
  instanceURLs.forEach(function(instanceURL) {
    requestInstance(instanceURL, function(arrayBuffer) {
      let dataset = readDICOM(arrayBuffer);
      seriesDatasets.push(dataset);
      step.ui.bottomBar.progress = `Loaded ${seriesDatasets.length} of ${instanceURLs.length}`;
      if (seriesDatasets.length == instanceURLs.length) {
        step.ui.bottomBar.progress = `All ${instanceURLs.length} datasets retrieved`;
        loadDatasets(seriesDatasets);
      }
    });
  });
}

function updateGradientOpacity(value) {
  updateTransferFunction({gradientOpacityScale: value});
}

function updateTransferFunction(options = {}) {
  let field = options.field || step.controls.selectedImageField();
  if (field) {
    let oldTFLength = field.transferFunction.length;
    let transferFunction = step.tf.getTF();
    let fixedTransferFunction = JSON.parse(JSON.stringify(transferFunction));
    fixedTransferFunction.forEach(point => {
      point[1].r /= 255;
      point[1].g /= 255;
      point[1].b /= 255;
    });
    field.transferFunction = fixedTransferFunction;
    if (oldTFLength != field.transferFunction.length) {
      step.renderer.updateProgram();
    }
    if (options.gradientOpacityScale) {
      field.gradientOpacityScale = options.gradientOpacityScale;
    }
    step.renderer.requestRender();
  }
}

function performImageFilter( generator, options ) {
  options.filterField = options.filterField ||
    step.renderer.inputFields.find((field) => field.constructor.name == "ImageField");

  if (!options.filterField || options.filterField.constructor.name != "ImageField") {
    alert('Need to load an image field');
    return (options);
  }

  options.derivedImage = new DerivedImage([options.filterField.dataset]);
  options.derivedField0 = Field.fromDataset(options.derivedImage.dataset)[0];

  // override default calculation
  options.derivedField0.windowCenter = options.filterField.windowCenter;
  options.derivedField0.windowWidth = options.filterField.windowWidth;
  options.derivedField0.generatedPixelData = options.derivedField0.dataset.PixelData;

  let originalInputFields = step.renderer.inputFields.slice();
  step.renderer.inputFields = [options.filterField, options.derivedField0];
  step.renderer.updateProgram();

  options.generator = new generator({
    gl: step.renderer.gl,
    inputFields: [options.filterField],
    outputFields: [options.derivedField0],
    options: options
  });

  options.generator.gl = step.renderer.gl;
  options.generator.inputFields = [options.filterField];
  options.generator.outputFields = [options.derivedField0];
  Object.keys(options.uniforms).forEach(uniformKey =>
    options.generator.uniforms[uniformKey] = options.uniforms[uniformKey]);
  options.generator.updateProgram();

  console.log(`image filtering with `, options.generator);
  options.generator.generate();
  options.derivedField0.dataset.PixelData = new Int16Array(options.derivedField0.generatedPixelData);

  step.renderer._render();
  options.filterField.visible = 0;
  options.derivedField0.visible = 1;
  step.renderer.inputFields = originalInputFields;
  step.renderer.inputFields.push(options.derivedField0);
  step.renderer.requestRender(step.view);

  return (options);
}

function performBilateral(options) {
  options.sigmaRange = options.sigmaRange || 1000.;
  options.sigmaSpace = options.sigmaSpace || 5.;
  options.kernelSize = options.kernelSize || 3.;

  options.uniforms = {};
  options.uniforms.sigmaRange = {type: '1f', value: options.sigmaRange};
  options.uniforms.sigmaSpace = {type: '1f', value: options.sigmaSpace};
  options.uniforms.kernelSize = {type: '1i', value: options.kernelSize};
  return (performImageFilter(BilateralGenerator, options));
}

function performSimilarity(options) {
  options.fiducialField = options.fiducialField ||
    step.renderer.inputFields.find((field) => field.constructor.name == "FiducialField");
  if (options.fiducialField) {
    options.referencePatientCoordinate = options.fiducialField.fiducials[0].point;
  }
  options.referencePatientCoordinate = options.referencePatientCoordinate || [.5, .5, .5];
  options.rotationSamples = options.rotationSamples || 10;
  options.kernelSize = options.kernelSize || 5;

  options.uniforms = {};
  options.uniforms.referencePatientCoordinate = {type: '3fv', value: options.referencePatientCoordinate};
  options.uniforms.rotationSamples = {type: '1i', value: options.rotationSamples};
  options.uniforms.kernelSize = {type: '1i', value: options.kernelSize};
  return (performImageFilter(SimilarityGenerator, options));
}

function performGabor(options) {
  options.sigma = options.sigma || 1;
  options.frequency = options.frequency || 1;
  options.phase = options.phase || 0;
  options.kernelSize = options.kernelSize || 5;
  options.rotationSample = options.rotationSample || 0;

  options.uniforms = {};
  options.uniforms.sigma = {type: '1f', value: options.sigma};
  options.uniforms.frequency = {type: '1f', value: options.frequency};
  options.uniforms.phase = {type: '1f', value: options.phase};
  options.uniforms.kernelSize = {type: '1i', value: options.kernelSize};
  options.uniforms.rotationSample = {type: '1i', value: options.rotationSample};
  options = performImageFilter(GaborGenerator, options);
  options.generator.outputFields[0].windowCenter = 0;
  options.generator.outputFields[0].windowWidth = 200;
  options.generator.outputFields[0].gradientOpacityScale = 0.;

  return (options);
}

function animateGabor(options={}) {
  let frame = 0;
  let frames = options.frames || 7;
  let animationFrame = function (now) {
    performGabor({rotationSample: frame});
    step.renderer.requestRender();
    step.ui.bottomBar.progress = `Gabor sampleNumber ${frame} of ${frames}`;
    frame = frame + 1;
    if (frame <= frames) {
      requestAnimationFrame(animationFrame)
    }
  };
  requestAnimationFrame(animationFrame)
}

function performNonlocalmeans(options) {
  return (performImageFilter(NonLocalMeansGenerator, options));
}


function performPDE(options) {
  options = options || {};
  options.deltaT = options.deltaT || 1.;
  options.edgeWeight = options.edgeWeight || 1.;
  options.iterations = options.iterations || 100;

  let filterField = step.renderer.inputFields[0];
  if (!filterField || filterField.constructor.name != "ImageField") {
    alert('Need to load an image field');
    return;
  }
  filterField.visible = 1;

  let derivedImage = new DerivedImage([filterField.dataset]);
  let derivedFields = [];
  derivedFields[0] = Field.fromDataset(derivedImage.dataset)[0];
  derivedFields[1] = Field.fromDataset(derivedImage.dataset)[0];

  // override default calculation
  derivedFields[0].windowCenter = filterField.windowCenter;
  derivedFields[0].windowWidth = filterField.windowWidth;
  derivedFields[1].windowCenter = filterField.windowCenter;
  derivedFields[1].windowWidth = filterField.windowWidth;

  step.renderer.inputFields = [filterField, derivedFields[0], derivedFields[1]];
  step.renderer.updateProgram();

  step.generator = new PDEGenerator({
    uniforms: {
      deltaT : { type: '1f', value: options.deltaT },
      edgeWeight : { type: '1f', value: options.edgeWeight },
      iterations : { type: '1i', value: options.iterations },
      iteration : { type: '1i', value: 0 },
    },
    gl: step.renderer.gl,
    inputFields: [filterField, derivedFields[0]],
    outputFields: [derivedFields[1]],
  });
  step.generator.updateProgram();

  let iterations = options.iterations;
  let iteration = 0;
  let renderRate = 1;
  let animationFrame = function() {
    step.ui.bottomBar.progress = `Iteration ${iteration} of ${iterations}`;
    let inputPhi = derivedFields[iteration%2];
    inputPhi.visible = 0;
    let outputPhi = derivedFields[(iteration+1)%2];
    outputPhi.visible = 1;
    step.generator.uniforms.iteration.value = iteration;
    step.generator.inputFields = [filterField, inputPhi];
    step.generator.outputFields =  [outputPhi];
    step.generator.generate();
    ++iteration;
    if (iteration % renderRate == 0) {
      step.renderer._render();
      let gl = step.renderer.gl;
    }
    if (iteration <= iterations) {
      requestAnimationFrame(animationFrame);
    } else {
      step.renderer._render();
      step.ui.bottomBar.progress = `Finished ${iterations} iterations`;
    }
  }
  animationFrame(iteration);

  return(options);
}

function performGrowCut() {
  console.log('starting performGrowCut');
  let backgroundField = step.renderer.inputFields[step.renderer.inputFields.length-1];
  if (!backgroundField || backgroundField.constructor.name != "ImageField") {
    alert('Need to have a background image field');
    return;
  }

  let labelFields = [];
  let strengthFields = [];
  [0,1].forEach(index=>{
    let derivedImage = new DerivedImage([backgroundField.dataset]);
    let labelField = Field.fromDataset(derivedImage.dataset)[0];
    let strengthField = Field.fromDataset(derivedImage.dataset)[0];
    labelFields.push(labelField);
    strengthFields.push(strengthField);
    step.renderer.inputFields.push(labelField);
    step.renderer.inputFields.push(strengthField);
    console.log('added field', index);
  });
  // TODO: don't need to upload texture of generated fields
  step.renderer.updateProgram();

  console.log('updated program');

  let iterationMode = 'animated';
  backgroundField.visible = 0;
  let iterations = 50;
  let iteration = 0;
  let animationFrame = function() {

    let inBuffer = iteration%2;
    let outBuffer = (iteration+1)%2;

    if (!step.growcut) {
      step.growcut = new GrowCutGenerator({
        gl: step.renderer.gl,
      });
      step.growcut.uniforms.iterations.value = iterations;
      step.growcut.inputFields = [backgroundField,
                                  labelFields[inBuffer],
                                  strengthFields[inBuffer]];
      step.growcut.outputFields = [labelFields[outBuffer],
                                   strengthFields[outBuffer]];
      step.growcut.updateProgram();
    }
    step.growcut.uniforms.iteration.value = iteration;

    labelFields[inBuffer].visible = 0;
    strengthFields[inBuffer].visible = 0;
    labelFields[outBuffer].visible = 1;
    strengthFields[outBuffer].visible = 0;

    console.log(iteration,'generating');
    step.growcut.inputFields = [backgroundField,
                                labelFields[inBuffer],
                                strengthFields[inBuffer]];
    step.growcut.outputFields = [labelFields[outBuffer],
                                 strengthFields[outBuffer]];

    // for the final iteration, save the calculation result to CPU
    if (iteration == iterations-1) {
      step.growcut.outputFields.forEach(outputField => {
        outputField.generatedPixelData = outputField.dataset.PixelData;
      });
    }

    step.growcut.generate();

    console.log(iteration,'rendering');
    step.renderer._render();

    iteration++;

    if (iteration < iterations) {
      // not finished, trigger another itertion
      step.ui.bottomBar.progress = `Iteration ${iteration} of ${iterations}`;
      if (iterationMode == 'animated') {
        requestAnimationFrame(animationFrame); // continue iterating
      }
    } else {
      step.ui.bottomBar.progress = `Finished ${iterations} iterations`;
      [0,1].forEach(index=>{
        labelFields[index].visible = 0;
        strengthFields[index].visible = 0;
      });
      backgroundField.visible = 1;
      labelFields[outBuffer].visible = 1;
      step.renderer._render();
      console.log('finished');
    }
  }
  if (iterationMode == 'animated') {
    requestAnimationFrame(animationFrame); // start the iterations
  } else {
    for (let i = 0; i < iterations; i++) {
      animationFrame();
    }
  }

  step.renderer.requestRender(step.view);
}

// hard coded for testing
function performRegistration() {
  console.log('starting performRegistration');

  // for easier testing: last field with transform is moving, last without is fixed
  // - compatible with data loaded from slicer or manually created
  let fixedField, movingField, deformationField;
  step.renderer.inputFields.forEach(inputField => {
    if (inputField.constructor.name == "ImageField") {
      if (inputField.transformField) {
        movingField = inputField;
        deformationField = inputField.transformField;
      } else {
        fixedField = inputField;
      }
    }
  });

  if ( !deformationField && step.renderer.inputFields.length > 1 ) {
    fixedField = step.renderer.inputFields[0];
    movingField = step.renderer.inputFields[1];
    addTransformField({referenceField: movingField});
    deformationField = movingField.transformField;
  }

  if ( !(fixedField && movingField && deformationField) ) {
    alert("Couldn't find fields for registration");
    return;
  }

  // if there's a second transform already, use it otherwise create one
  let secondDeformationField;
  step.renderer.inputFields.forEach(inputField => {
    if (inputField.constructor.name == "TransformField" && inputField != deformationField) {
      secondDeformationField = inputField;
    }
  });
  if (!secondDeformationField) {
    // when making a copy, handle the heavyweight vector data independently
    let sourceGrid = deformationField.dataset.DeformableRegistration.DeformableRegistrationGrid;
    let savedGridData = sourceGrid.VectorGridData;
    sourceGrid.VectorGridData = undefined;
    let datasetCopy = JSON.parse(JSON.stringify(deformationField.dataset));
    sourceGrid.VectorGridData = savedGridData;
    let copyGrid = datasetCopy.DeformableRegistration.DeformableRegistrationGrid;
    copyGrid.VectorGridData = new Float32Array(savedGridData);
    datasetCopy.SeriesDescription = "Copied Deformation";
    let deformationFieldCopy = Field.fromDataset(datasetCopy)[0];
    step.renderer.inputFields.unshift(deformationFieldCopy);
    secondDeformationField = deformationFieldCopy;
  }

  let deformationFields = [deformationField, secondDeformationField];
  deformationFields.forEach(deformationField => deformationField.visible = 0);
  movingField.transformGain = 1.;

  step.renderer.updateProgram();
  step.renderer.requestRender(step.view);

  let iterationMode = 'animated';
  let iterations = 50;
  let iteration = 0;
  let animationFrame = function() {

    let inBuffer = iteration%2;
    let outBuffer = (iteration+1)%2;

    let needUpdate = false;
    if (!step.registration) {
      step.registration = new RegistrationGenerator({
        gl: step.renderer.gl,
      });
      needUpdate = true;
    }
    step.registration.uniforms.iteration.value = iteration;
    step.registration.uniforms.iterations.value = iterations;
    step.registration.inputFields = [deformationFields[inBuffer],
                                     fixedField,
                                     movingField];
    step.registration.outputFields = [deformationFields[outBuffer]];
    if (needUpdate) {
      step.registration.updateProgram();
    }

    // for the final iteration, save the calculation result to CPU
    /* TODO: handle generated VectorGridData
       - note that texture is 4 component RGBA but transformField.dataset grid is 3 component
    if (iteration == iterations-1) {
      step.registration.outputFields.forEach(outputField => {
        outputField.generatedPixelData = outputField.dataset.PixelData;
      });
    }
    */

    step.registration.generate();
    step.renderer._render();
    iteration++;

    if (iteration < iterations) {
      // not finished, trigger another itertion
      step.ui.bottomBar.progress = `Iteration ${iteration} of ${iterations}`;
      if (iterationMode == 'animated') {
        step.renderer.requestRender(step.view);
        requestAnimationFrame(animationFrame); // continue iterating
      }
    } else {
      step.ui.bottomBar.progress = `Finished ${iterations} iterations`;
      step.renderer._render();
      console.log('finished');
    }
  }

  //
  // perform the iteration using either requestAnimationFrame or loop
  //
  if (iterationMode == 'animated') {
    requestAnimationFrame(animationFrame); // start the iterations
  } else {
    for (let i = 0; i < iterations; i++) {
      animationFrame();
    }
  }

  step.renderer.requestRender(step.view);
}

let step = {
  options : {
    newVolumeThreeD : false,
  },
  uniforms : {
    pointLight: { type: '3fv', value: [100., -400., 1500.] },
    gradientSize: { type: '1f', value: 1. },
    rayMaxSteps: { type: '1i', value: 10000 },
    sampleStep: { type: '1f', value: 0.5 },
    renderCanvasWidth: { type: '1f', value: 512 },
    renderCanvasHeight: { type: '1f', value: 512 },
    sliceMode: { type: '1i', value: 1 },
    Kambient: { type: '1f', value: 1.5 },
    Kdiffuse: { type: '1f', value: .95 },
    Kspecular: { type: '1f', value: .8 },
    Shininess: { type: '1f', value: 10 },
  },
};

// once document is loaded...
$(function () {

  //
  // renderer
  //
  let canvas = document.querySelector('#renderCanvas');
  let gl = canvas.getContext('webgl2');

  if (!gl) {
    alert('Sorry, it looks like your browser does not support webgl2.  Try firefox.');
    return;
  }
  $('#noWebGLAlert').remove();


  // check if our gl supports float textures and if
  // so set the Field and Generator class variables so all instances use
  // the same type
  let glExtensions = {};
  let expectedExtensions = [
    "EXT_color_buffer_float",
    "OES_texture_float_linear",
  ]; /* TODO WEBGL_debug_renderer_info WEBGL_lose_context */
  expectedExtensions.forEach(extensionName => {
    glExtensions[extensionName] = gl.getExtension(extensionName);
  });

  let hasTextureFloatLinear = 'OES_texture_float_linear' in glExtensions;
  let hasColorBufferFloat = 'EXT_color_buffer_float' in glExtensions;
  Field.useIntegerTextures = !(hasTextureFloatLinear && hasColorBufferFloat);
  if (Field.useIntegerTextures) {
    // TODO: this mode should probably go away in order to simplify the code
    // https://webglstats.com/webgl2/extension/OES_texture_float_linear
    console.warn('Floating texture support not available');
  }
  Generator.useIntegerTextures = Field.useIntegerTextures;

  /*
  Field.useIntegerTextures = true; // debug
  Generator.useIntegerTextures = true; // debug
  */

  step.renderer = new RayCastRenderer({
    gl,
    canvas,
    uniforms: step.uniforms,
    inputFields: [],
  });
  step.view = new View({
    viewBoxMax : [250, 250, -250],
    viewBoxMin : [-250, -250, -200],
    viewPoint : [0., -400., 0.],
    viewNormal : [0., 1., 0.],
    viewUp : [0., 0., 1.],
  });
  step.renderer.glExtensions = glExtensions;
  step.renderer.updateProgram();
  step.renderer._render(step.view);

  window.addEventListener('resize', resizeEvent => {
    renderCanvas.width = window.innerWidth;
    renderCanvas.height = window.innerHeight;
    step.uniforms.renderCanvasWidth.value = renderCanvas.width;
    step.uniforms.renderCanvasHeight.value = renderCanvas.height;
    if (step.renderer) {
      step.renderer.requestRender(step.view);
    }
  });
  window.dispatchEvent(new Event('resize'));


  //
  // chronicle
  // - database selection interface
  // - operation performer
  //
  step.chronicle = new Chronicle({url: 'http://quantome.org:5984/chronicle'});
  step.operationPerformer = new OperationPerformer({dbURL: 'http://quantome.org:5984/operations'});

  //
  // user interface elements
  //
  step.ui = {};
  step.ui.menubar = new stepMenubar(step, {
    chronicle : step.chronicle,
    requestSeries : requestSeries,
    updateTransferFunction : updateTransferFunction,
    onGradientOpacityScaleChange : (event) => {updateGradientOpacity(event.target.value)},
    performPDE : performPDE,
    performGrowCut : performGrowCut,
    performBilateral : performBilateral,
    performSimilarity : performSimilarity,
    performGabor : performGabor,
    performNonlocalmeans : performNonlocalmeans,
    performRegistration : performRegistration,
    addRandomFiducials : addRandomFiducials,
    loadVolumeFromSlicer : loadVolumeFromSlicer,
    loadVolumesFromSlicer : loadVolumesFromSlicer,
    sendVolumesToSlicer : sendVolumesToSlicer,
    addTransformField : addTransformField,
    fiducialsFromSlicer : fiducialsFromSlicer,
    animateTransform : animateTransform,
    save : saveFieldsAsDICOM,
  });
  document.body.insertBefore(step.ui.menubar.dom, document.body.firstChild);

  step.ui.bottomBar = new stepBottomBar(step, {
    onSliceOffetChange : function(event){
      console.log(event.target.value);
    },
  });
  document.body.appendChild(step.ui.bottomBar.dom);

  step.ui.sideBar = new stepSideBar(step, {
  });
  document.body.appendChild(step.ui.sideBar.dom);

  //
  // interactive controls
  //
  step.controls = new Controls();
  step.controls.activate({
    onWindowLevel: step.ui.sideBar.drawHistogram
  });

  let toolSelectUI = step.ui.bottomBar.toolSelectUI;
  toolSelectUI.dom.addEventListener('change', event => {
    step.controls.tool = toolSelectUI.getValue();
  });


});

let onResize = function() {
  renderCanvas.width = window.innerWidth;
  renderCanvas.height = window.innerHeight;
}
onResize();
window.onresize = onResize;

</script>

<div id="noWebGLAlert">
  <p>
  This demo uses <a href='https://www.khronos.org/registry/webgl/specs/latest/2.0/'>WebGL2</a>.  Not all devices and browsers are supported.  As of this writing only the latest Chrome Canary or Firefox Nightly will work.  <a href='https://www.khronos.org/webgl/wiki/Getting_a_WebGL_Implementation'>See this page for details.</a>
  </p>
  <p>This <a href='http://www.youtube.com/embed/wMkuwzA7RDo'>video</a> shows what the project looks like when WebGL2 is available.</p>
</div>

</body>
</html>
